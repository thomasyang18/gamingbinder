# Impermanance and Mental Models    

Date: 12-4-2024

---

I think as I've done more competitive programming I've really come to just appreciate just how much context is needed to enjoy some of these problems, and the difference between hidden and open information. I think that may be at the crux of some of my hangups when it comes to gaming. 

Like, obviously you have the algorithms themselves, but often the point of competitive programming problems is that it's:

- implementable in a few hours (ideally an hour at most)
- has a simple enough idea to where, at the appropriate level, you can find the solution to it in a few hours, and probably upper bound a week or so if you really had the time/energy to ruminate on it 
- **not one shottable by some standard technique**, which is at odds with normal engineering, aimed to solve the general case most of the time
    - For example, you may be using the technique of binary search, but you're not literally binary searching on an array over and over
    - Whereas me when I throw machine learning / basic data structures / basic systems over and over again 
    - It's not a good problem if the solution isn't clever, right? 
    - Even often in research too, you're pulling a lot of machinery to get things to work 

At the same time, there's something a lot more pure about open-information activities, like games, like math, etc. 

(I talk about this from the perspective of academia, but obviously this microcosm extends to gaming subcommunities and probably many other subcommunities as well, just understand the general concept)

---

Well, I guess there's open information, but the idea or skill needed is just hard inherently. I mean I can try to break it down, but that's not really the point of this essay. For example, papers are a form of information that theoretically anybody could understand, because the information is right there, but it can just be hard to slog through it. Anyone can theoretically shoot 3 pointers, but it's just hard. 
    
I would say the quintessential example is, if X is debating Y about the subject, can X prove Y wrong by just saying "no, you're just not understanding this fundamental truth", or does X prove Y wrong by saying, "no, this real life study disproves your intuition." I guess it can also be a fine line between counterexamples and intuition, but like, I guess I equate it to like, can you debunk them based on information already out in the open shared in the field, e.g. "your algorithm is wrong because line X Y Z is sus" versus "I have this random paper from 1995 that did this exact study" (though IG implicitly both parties think of a counter-example right then and there). In one instance, the learning is very much baked into the process, in the other, it's as if you're just suddenly dropped the fact that "the sun is actually the center of the universe" after being sold on geocentrism your whole life or something. 

Although even in that case it's inaccurate, since nowadays we have enough tools such that you can verify that pretty easily (unless you believe all of science is against you and all our tools are fake, which is easy to rule out by occam's razor). When it comes to something like the social sciences, they're equally as important, if not more, yet it's hard to come to hard conclusions about it because of reproducibility. 

---

Speaking of science, there's two kinds of open information - I guess soft and hard? Like we invented a bunch of math and can invent more useless math to solve problems, and can build context out of that. But there's no way of squirming out of, say, "a baby grows in 9 months". I mean, sure, we can try genetic engineering, etc. but that context is just something you have to accept if you want to be a doctor or do anything related to human biology, for example. I avoid using physics analogies here since I want to point out that this kind of information happens in all kinds of contexts, even though, as I've pointed out, a baby growing in 9 months isn't necessarily a fundamental truth of the universe that must be true for all human beings ever, but yeah some fundamental assumptions, even if they suck, are just truths. 

I guess you could argue that if P != NP, it's similar, so maybe this point is just moot entirely. [But hear me out on the buildup here]

---

Then there's semi-closed information. This is just most information, I think (and I guess open information, like papers, can also fall under this category). Nobody's actively stopping you from finding it, but just because the search space is so vast it's hard to stumble across it. Plus, different contexts can make you compatible or not with certain information. This is things like, codified information in discords, or knowledge cooped up in a professor's brain, an obscure blog community, etc. and you just have to work at it to track down the right people for the right information that you think you're looking for. 

---

Then there's just closed information. Software, engineering, and architectural decisions are like this. Actually I think pretty much all products are like this. Open information is the most timeless, people always complain about how they're not going to get the experience they used to back then. 

I mean there's also obviously logistical concerns as well, obviously how tf are you going to get exactly the same ingredients as you did 50 years ago. But IDK, I think this is why people get so depressed when they have to stare down a million line codebase that they're not familiar with, or at least I do. I haven't done engineering work so I can't comment on that. 

Like, for example, internet protocols are a great example of open information, their implementations? uhh.... lol. I guess this is why we have standards, so you can (theoretically) logically deduce the consequences of what should theoretically go on with the abstraction, as opposed to the impl, but obviously this has direct rammifications (the STL optimizes for good enough in most situations, and a damn good job at that, but specialized sorting routines need specialized algorithms).

People want to get rewarded for their work, shocker (IP, patents, trading strategies, etc.), and in a competitive world, there's just that need to keep information secret.  Also, even in a cooperative one, people don't want to think about all the details all the time, not just for efficiency reasons but also because they want to spend more time doing the things they like, so everybody wins. 

# Conclusion 

So yeah. I think the most important thing I said in that entire post is the paragraph about X debating Y, that's the type of information transfer that feels good to me, and what I want games to have. 

Though again, everything has some underlying context if you design for it that way. 

